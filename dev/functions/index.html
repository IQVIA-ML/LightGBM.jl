<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Functions · LightGBM.jl</title><meta name="title" content="Functions · LightGBM.jl"/><meta property="og:title" content="Functions · LightGBM.jl"/><meta property="twitter:title" content="Functions · LightGBM.jl"/><meta name="description" content="Documentation for LightGBM.jl."/><meta property="og:description" content="Documentation for LightGBM.jl."/><meta property="twitter:description" content="Documentation for LightGBM.jl."/><meta property="og:url" content="https://IQVIA-ML.github.io/LightGBM.jl/functions/"/><meta property="twitter:url" content="https://IQVIA-ML.github.io/LightGBM.jl/functions/"/><link rel="canonical" href="https://IQVIA-ML.github.io/LightGBM.jl/functions/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LightGBM.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Functions</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/master/docs/src/functions.md#L" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Functions"><a class="docs-heading-anchor" href="#Functions">Functions</a><a id="Functions-1"></a><a class="docs-heading-anchor-permalink" href="#Functions" title="Permalink"></a></h1><ul><li><a href="#LightGBM.LGBMClassification-Tuple{}"><code>LightGBM.LGBMClassification</code></a></li><li><a href="#LightGBM.LGBMRegression-Tuple{}"><code>LightGBM.LGBMRegression</code></a></li><li><a href="#LightGBM.LGBM_BoosterUpdateOneIterCustom-Tuple{LightGBM.Booster, Vector{&lt;:AbstractFloat}, Vector{&lt;:AbstractFloat}}"><code>LightGBM.LGBM_BoosterUpdateOneIterCustom</code></a></li><li><a href="#LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, Matrix{TX}, Vector{Ty}, Any}} where {TX&lt;:Real, Ty&lt;:Real}"><code>LightGBM.cv</code></a></li><li><a href="#LightGBM.fit!-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, AbstractMatrix{TX}, Vector{Ty}, Vararg{Tuple{AbstractMatrix{TX}, Vector{Ty}}}}} where {TX&lt;:Real, Ty&lt;:Real, Tw&lt;:Real, Ti&lt;:Real}"><code>LightGBM.fit!</code></a></li><li><a href="#LightGBM.gain_importance-Tuple{LGBMEstimator, Integer}"><code>LightGBM.gain_importance</code></a></li><li><a href="#LightGBM.loadmodel!-Tuple{LGBMEstimator, String}"><code>LightGBM.loadmodel!</code></a></li><li><a href="#LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator, AbstractMatrix{TX}}} where TX&lt;:Real"><code>LightGBM.predict</code></a></li><li><a href="#LightGBM.savemodel-Tuple{LGBMEstimator, String}"><code>LightGBM.savemodel</code></a></li><li><a href="#LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, Matrix{TX}, Vector{Ty}, Any, Any}} where {TX&lt;:Real, Ty&lt;:Real}"><code>LightGBM.search_cv</code></a></li><li><a href="#LightGBM.split_importance-Tuple{LGBMEstimator, Integer}"><code>LightGBM.split_importance</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.LGBMClassification-Tuple{}" href="#LightGBM.LGBMClassification-Tuple{}"><code>LightGBM.LGBMClassification</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">LGBMClassification(;[
    objective = &quot;multiclass&quot;,
    boosting = &quot;gbdt&quot;,
    num_iterations = 10,
    learning_rate = .1,
    num_leaves = 127,
    max_depth = -1,
    tree_learner = &quot;serial&quot;,
    num_threads = Sys.CPU_THREADS,
    histogram_pool_size = -1.,
    min_data_in_leaf = 100,
    min_sum_hessian_in_leaf = 1e-3,
    max_delta_step = 0.,
    lambda_l1 = 0.,
    lambda_l2 = 0.,
    min_gain_to_split = 0.,
    feature_fraction = 1.,
    feature_fraction_bynode = 1.,
    feature_fraction_seed = 2,
    bagging_fraction = 1.,
    pos_bagging_fraction = 1.,
    neg_bagging_fraction = 1.,
    bagging_freq = 0,
    bagging_seed = 3,
    early_stopping_round = 0,
    extra_trees = false,
    extra_seed = 6,
    max_bin = 255,
    bin_construct_sample_cnt = 200000,
    data_random_seed = 1,
    init_score = &quot;&quot;,
    is_sparse = true,
    save_binary = false,
    categorical_feature = Int[],
    use_missing = true,
    linear_tree = false,
    is_unbalance = false,
    boost_from_average = true,
    scale_pos_weight = 1.0,
    sigmoid = 1.0,
    drop_rate = 0.1,
    max_drop = 50,
    skip_drop = 0.5,
    xgboost_dart_mode = false,
    uniform_drop = false,
    drop_seed = 4,
    top_rate = 0.2,
    other_rate = 0.1,
    min_data_per_group = 100,
    max_cat_threshold = 32,
    cat_l2 = 10.0,
    cat_smooth = 10.0,
    metric = [&quot;multi_logloss&quot;],
    metric_freq = 1,
    is_training_metric = false,
    ndcg_at = Int[],
    num_machines = 1,
    local_listen_port = 12400,
    time_out = 120,
    machine_list_file = &quot;&quot;,
    num_class = 1,
    device_type=&quot;cpu&quot;,
    gpu_use_dp = false,
    gpu_platform_id = -1,
    gpu_device_id = -1,
    num_gpu = 1,
    force_col_wise = false,
    force_row_wise = false,
])</code></pre><p>Return a LGBMClassification estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/estimators.jl#LL319-L391">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.LGBMRegression-Tuple{}" href="#LightGBM.LGBMRegression-Tuple{}"><code>LightGBM.LGBMRegression</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">LGBMRegression(; [
    objective = &quot;regression&quot;,
    boosting = &quot;gbdt&quot;,
    num_iterations = 10,
    learning_rate = .1,
    num_leaves = 127,
    max_depth = -1,
    tree_learner = &quot;serial&quot;,
    num_threads = Sys.CPU_THREADS,
    histogram_pool_size = -1.,
    min_data_in_leaf = 100,
    min_sum_hessian_in_leaf = 1e-3,
    max_delta_step = 0.,
    lambda_l1 = 0.,
    lambda_l2 = 0.,
    min_gain_to_split = 0.,
    feature_fraction = 1.,
    feature_fraction_bynode = 1.,
    feature_fraction_seed = 2,
    bagging_fraction = 1.,
    bagging_freq = 0,
    bagging_seed = 3,
    early_stopping_round = 0,
    extra_trees = false
    extra_seed = 6,
    max_bin = 255,
    bin_construct_sample_cnt = 200000,
    data_random_seed = 1,
    init_score = &quot;&quot;,
    is_sparse = true,
    save_binary = false,
    categorical_feature = Int[],
    use_missing = true,
    linear_tree = false,
    feature_pre_filter = true,
    is_unbalance = false,
    boost_from_average = true,
    alpha = 0.9,
    drop_rate = 0.1,
    max_drop = 50,
    skip_drop = 0.5,
    xgboost_dart_mode = false,
    uniform_drop = false,
    drop_seed = 4,
    top_rate = 0.2,
    other_rate = 0.1,
    min_data_per_group = 100,
    max_cat_threshold = 32,
    cat_l2 = 10.0,
    cat_smooth = 10.0,
    metric = [&quot;l2&quot;],
    metric_freq = 1,
    is_training_metric = false,
    ndcg_at = Int[],
    num_machines = 1,
    local_listen_port = 12400,
    time_out = 120,
    machine_list_file = &quot;&quot;,
    device_type=&quot;cpu&quot;,
    gpu_use_dp = false,
    gpu_platform_id = -1,
    gpu_device_id = -1,
    num_gpu = 1,
    force_col_wise = false
    force_row_wise = false
])</code></pre><p>Return a LGBMRegression estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/estimators.jl#LL82-L151">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.LGBM_BoosterUpdateOneIterCustom-Tuple{LightGBM.Booster, Vector{&lt;:AbstractFloat}, Vector{&lt;:AbstractFloat}}" href="#LightGBM.LGBM_BoosterUpdateOneIterCustom-Tuple{LightGBM.Booster, Vector{&lt;:AbstractFloat}, Vector{&lt;:AbstractFloat}}"><code>LightGBM.LGBM_BoosterUpdateOneIterCustom</code></a> — <span class="docstring-category">Method</span></header><section><div><p>LGBM_BoosterUpdateOneIterCustom Pass grads and 2nd derivatives corresponding to some custom loss function grads and 2nd derivatives must be same cardinality as training data * number of models Also, trying to run this on a booster without data will fail.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/wrapper.jl#LL470-L475">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, Matrix{TX}, Vector{Ty}, Any}} where {TX&lt;:Real, Ty&lt;:Real}" href="#LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, Matrix{TX}, Vector{Ty}, Any}} where {TX&lt;:Real, Ty&lt;:Real}"><code>LightGBM.cv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">cv(estimator, X, y, splits; [verbosity = 1])</code></pre><p>Cross-validate the <code>estimator</code> with features data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides vectors of indices for the training dataset. The remaining indices are used to create the validation dataset. Alternatively, cv can be called with an input Dataset class</p><p>Return a dictionary with an entry for the validation dataset and, if the parameter <code>is_training_metric</code> is set in the <code>estimator</code>, an entry for the training dataset. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value for each dataset, at the last valid iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>dataset::Dataset</code>: prepared dataset (either (X, y), or dataset needs to be specified as input)</li><li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/cv.jl#LL1-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.fit!-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, AbstractMatrix{TX}, Vector{Ty}, Vararg{Tuple{AbstractMatrix{TX}, Vector{Ty}}}}} where {TX&lt;:Real, Ty&lt;:Real, Tw&lt;:Real, Ti&lt;:Real}" href="#LightGBM.fit!-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, AbstractMatrix{TX}, Vector{Ty}, Vararg{Tuple{AbstractMatrix{TX}, Vector{Ty}}}}} where {TX&lt;:Real, Ty&lt;:Real, Tw&lt;:Real, Ti&lt;:Real}"><code>LightGBM.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">fit!(estimator, num_iterations, X, y[, test...]; [verbosity = 1, is_row_major = false])
fit!(estimator, X, y[, test...]; [verbosity = 1, is_row_major = false])
fit!(estimator, X, y, train_indices[, test_indices...]; [verbosity = 1, is_row_major = false])
fit!(estimator, train_dataset[, test_datasets...]; [verbosity = 1])</code></pre><p>Fit the <code>estimator</code> with features data <code>X</code> and label <code>y</code> using the X-y pairs in <code>test</code> as validation sets. Alternatively, Fit the <code>estimator</code> with <code>train_dataset</code> and <code>test_datasets</code> in the form of Dataset class(es)</p><p>Return a dictionary with an entry for each validation set. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value at each iteration.</p><p><strong>Positional Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li>and either<ul><li><code>X::AbstractMatrix{TX&lt;:Real}</code>: the features data. May be a <code>SparseArrays.SparseMatrixCSC</code></li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>test::Tuple{AbstractMatrix{TX},Vector{Ty}}...</code>: (optional) contains one or more tuples of X-y pairs of   the same types as <code>X</code> and <code>y</code> that should be used as validation sets. May be a <code>SparseArrays.SparseMatrixCSC</code>   and can mix-and-match sparse/dense among these test and the train.</li></ul></li><li>or<ul><li><code>train_dataset::Dataset</code>: prepared train_dataset</li><li><code>test_datasets::Vector{Dataset}</code>: (optional) prepared test_datasets</li></ul></li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li><li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>   indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia&#39;s default).   Should be consistent across train/test. Does not apply to <code>SparseArrays.SparseMatrixCSC</code> or <code>Dataset</code> constructors.</li><li><code>weights::Vector{Tw&lt;:Real}</code>: the training weights.</li><li><code>init_score::Vector{Ti&lt;:Real}</code>: the init scores.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/fit.jl#LL1-L34">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.gain_importance-Tuple{LGBMEstimator, Integer}" href="#LightGBM.gain_importance-Tuple{LGBMEstimator, Integer}"><code>LightGBM.gain_importance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">gain_importance(estimator, num_iteration)
gain_importance(estimator)

Returns the importance of a fitted booster in terms of information gain across
all boostings, or up to `num_iteration` boostings</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/utils.jl#LL101-L107">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.loadmodel!-Tuple{LGBMEstimator, String}" href="#LightGBM.loadmodel!-Tuple{LGBMEstimator, String}"><code>LightGBM.loadmodel!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">loadmodel!(estimator, filename)</code></pre><p>Load the fitted model <code>filename</code> into <code>estimator</code>. Note that this only loads the fitted model—not the parameters or data of the estimator whose model was saved as <code>filename</code>.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>filename::String</code>: the name of the file that contains the model.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/utils.jl#LL50-L59">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator, AbstractMatrix{TX}}} where TX&lt;:Real" href="#LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator, AbstractMatrix{TX}}} where TX&lt;:Real"><code>LightGBM.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">predict(estimator, X; [predict_type = 0, num_iterations = -1, verbosity = 1,
is_row_major = false])</code></pre><p>Return a <strong>MATRIX</strong> with the labels that the <code>estimator</code> predicts for features data <code>X</code>. Use <code>dropdims</code> if a vector is required.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>X::Matrix{T&lt;:Real}</code>: the features data.</li><li><code>predict_type::Integer</code>: keyword argument that controls the prediction type. <code>0</code> for normal   scores with transform (if needed), <code>1</code> for raw scores, <code>2</code> for leaf indices, <code>3</code> for SHAP contributions.</li><li><code>num_iterations::Integer</code>: keyword argument that sets the number of iterations of the model to   use in the prediction. <code>&lt; 0</code> for all iterations.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li><li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>   indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia&#39;s default).</li><li><code>num_threads::Integer</code>: keyword argument specifying the number of threads to use   for prediction. Default is <code>-1</code> which reuses <code>num_threads</code> of the estimator.</li></ul><p>One can obtain some form of feature importances by averaging SHAP contributions across predictions, i.e. <code>mean(LightGBM.predict(estimator, X; predict_type=3); dims=1)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/predict.jl#LL2-L25">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.savemodel-Tuple{LGBMEstimator, String}" href="#LightGBM.savemodel-Tuple{LGBMEstimator, String}"><code>LightGBM.savemodel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">savemodel(estimator, filename; [num_iteration = -1])</code></pre><p>Save the fitted model in <code>estimator</code> as <code>filename</code>.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>filename::String</code>: the name of the file to save the model in.</li><li><code>num_iteration::Integer</code>: keyword argument that sets the number of iterations of the model that   should be saved. <code>&lt; 0</code> for all iterations.</li><li><code>start_iteration</code> : : Start index of the iteration that should be saved.</li><li><code>feature_importance_type</code> : Type of feature importance,   can be C<em>API</em>FEATURE<em>IMPORTANCE</em>SPLIT or C<em>API</em>FEATURE<em>IMPORTANCE</em>GAIN</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/utils.jl#LL24-L37">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, Matrix{TX}, Vector{Ty}, Any, Any}} where {TX&lt;:Real, Ty&lt;:Real}" href="#LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator, Matrix{TX}, Vector{Ty}, Any, Any}} where {TX&lt;:Real, Ty&lt;:Real}"><code>LightGBM.search_cv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">search_cv(estimator, X, y, splits, params; [verbosity = 1])</code></pre><p>Exhaustive search over the specified sets of parameter values for the <code>estimator</code> with features data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides vectors of indices for the training dataset. The remaining indices are used to create the validation dataset. Alternatively, search_cv can be called with an input Dataset class</p><p>Return an array with a tuple for each set of parameters value, where the first entry is a set of parameter values and the second entry the cross-validation outcome of those values. This outcome is a dictionary with an entry for the validation dataset and, if the parameter <code>is_training_metric</code> is set in the <code>estimator</code>, an entry for the training dataset. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value for each dataset, at the last valid iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>dataset::Dataset</code>: prepared dataset (either (X, y), or dataset needs to be specified as input)</li><li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li><li><code>params</code>: the iterable providing dictionaries of pairs of parameters (Symbols) and values to   configure the <code>estimator</code> with.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/search_cv.jl#LL1-L28">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="LightGBM.split_importance-Tuple{LGBMEstimator, Integer}" href="#LightGBM.split_importance-Tuple{LGBMEstimator, Integer}"><code>LightGBM.split_importance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">split_importance(estimator, num_iteration)
split_importance(estimator)

Returns the importance of a fitted booster in terms of number of times feature was
used in a split across all boostings, or up to `num_iteration` boostings</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/e5297e977a46d0b1f5390c5714b4dfb56a7b12ed/src/utils.jl#LL112-L118">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.4.1 on <span class="colophon-date" title="Wednesday 8 May 2024 12:55">Wednesday 8 May 2024</span>. Using Julia version 1.10.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
