<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Functions · LightGBM.jl</title><link rel="canonical" href="https://IQVIA-ML.github.io/LightGBM.jl/functions/index.html"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">LightGBM.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Functions</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Functions</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Functions</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/master/docs/src/functions.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Functions-1"><a class="docs-heading-anchor" href="#Functions-1">Functions</a><a class="docs-heading-anchor-permalink" href="#Functions-1" title="Permalink"></a></h1><ul><li><a href="#LightGBM.LGBMClassification-Tuple{}"><code>LightGBM.LGBMClassification</code></a></li><li><a href="#LightGBM.LGBMRegression-Tuple{}"><code>LightGBM.LGBMRegression</code></a></li><li><a href="#LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.cv</code></a></li><li><a href="#LightGBM.fit!-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Int64,Array{TX,2},Array{Ty,1},Vararg{Tuple{Array{TX,2},Array{Ty,1}},N} where N}} where Ti&lt;:Real where Tw&lt;:Real where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.fit!</code></a></li><li><a href="#LightGBM.gain_importance-Tuple{LGBMEstimator,Integer}"><code>LightGBM.gain_importance</code></a></li><li><a href="#LightGBM.loadmodel-Tuple{LGBMEstimator,String}"><code>LightGBM.loadmodel</code></a></li><li><a href="#LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator,AbstractArray{TX,2}}} where TX&lt;:Real"><code>LightGBM.predict</code></a></li><li><a href="#LightGBM.savemodel-Tuple{LGBMEstimator,String}"><code>LightGBM.savemodel</code></a></li><li><a href="#LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any,Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.search_cv</code></a></li><li><a href="#LightGBM.split_importance-Tuple{LGBMEstimator,Integer}"><code>LightGBM.split_importance</code></a></li></ul><article class="docstring"><header><a class="docstring-binding" id="LightGBM.LGBMClassification-Tuple{}" href="#LightGBM.LGBMClassification-Tuple{}"><code>LightGBM.LGBMClassification</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">LGBMClassification(;[
    objective = &quot;multiclass&quot;,
    boosting = &quot;gbdt&quot;,
    num_iterations = 10,
    learning_rate = .1,
    num_leaves = 127,
    max_depth = -1,
    tree_learner = &quot;serial&quot;,
    num_threads = Sys.CPU_THREADS,
    histogram_pool_size = -1.,
    min_data_in_leaf = 100,
    min_sum_hessian_in_leaf = 10.,
    lambda_l1 = 0.,
    lambda_l2 = 0.,
    min_gain_to_split = 0.,
    feature_fraction = 1.,
    feature_fraction_seed = 2,
    bagging_fraction = 1.,
    bagging_freq = 0,
    bagging_seed = 3,
    early_stopping_round = 0,
    max_bin = 255,
    data_random_seed = 1,
    init_score = &quot;&quot;,
    is_sparse = true,
    save_binary = false,
    categorical_feature = Int[],
    is_unbalance = false,
    drop_rate = 0.1,
    max_drop = 50,
    skip_drop = 0.5,
    xgboost_dart_mode = false,
    uniform_drop = false,
    drop_seed = 4,
    top_rate = 0.2,
    other_rate = 0.1,
    metric = [&quot;multi_logloss&quot;],
    metric_freq = 1,
    is_training_metric = false,
    ndcg_at = Int[],
    num_machines = 1,
    local_listen_port = 12400,
    time_out = 120,
    machine_list_file = &quot;&quot;,
    num_class = 1,
    device_type=&quot;cpu&quot;,
])</code></pre><p>Return a LGBMClassification estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/estimators.jl#LL235-L285">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.LGBMRegression-Tuple{}" href="#LightGBM.LGBMRegression-Tuple{}"><code>LightGBM.LGBMRegression</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">LGBMRegression(; [
    objective = &quot;regression&quot;,
    boosting = &quot;gbdt&quot;,
    num_iterations = 10,
    learning_rate = .1,
    num_leaves = 127,
    max_depth = -1,
    tree_learner = &quot;serial&quot;,
    num_threads = Sys.CPU_THREADS,
    histogram_pool_size = -1.,
    min_data_in_leaf = 100,
    min_sum_hessian_in_leaf = 10.,
    lambda_l1 = 0.,
    lambda_l2 = 0.,
    min_gain_to_split = 0.,
    feature_fraction = 1.,
    feature_fraction_seed = 2,
    bagging_fraction = 1.,
    bagging_freq = 0,
    bagging_seed = 3,
    early_stopping_round = 0,
    max_bin = 255,
    data_random_seed = 1,
    init_score = &quot;&quot;,
    is_sparse = true,
    save_binary = false,
    categorical_feature = Int[],
    is_unbalance = false,
    drop_rate = 0.1,
    max_drop = 50,
    skip_drop = 0.5,
    xgboost_dart_mode = false,
    uniform_drop = false,
    drop_seed = 4,
    top_rate = 0.2,
    other_rate = 0.1,
    metric = [&quot;l2&quot;],
    metric_freq = 1,
    is_training_metric = false,
    ndcg_at = Int[],
    num_machines = 1,
    local_listen_port = 12400,
    time_out = 120,
    machine_list_file = &quot;&quot;,
    device_type=&quot;cpu&quot;,
])</code></pre><p>Return a LGBMRegression estimator.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/estimators.jl#LL62-L111">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any}} where Ty&lt;:Real where TX&lt;:Real" href="#LightGBM.cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.cv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">cv(estimator, X, y, splits; [verbosity = 1])</code></pre><p>Cross-validate the <code>estimator</code> with features data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides vectors of indices for the training dataset. The remaining indices are used to create the validation dataset.</p><p>Return a dictionary with an entry for the validation dataset and, if the parameter <code>is_training_metric</code> is set in the <code>estimator</code>, an entry for the training dataset. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value for each dataset, at the last valid iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/cv.jl#LL1-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.fit!-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Int64,Array{TX,2},Array{Ty,1},Vararg{Tuple{Array{TX,2},Array{Ty,1}},N} where N}} where Ti&lt;:Real where Tw&lt;:Real where Ty&lt;:Real where TX&lt;:Real" href="#LightGBM.fit!-Union{Tuple{Ti}, Tuple{Tw}, Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Int64,Array{TX,2},Array{Ty,1},Vararg{Tuple{Array{TX,2},Array{Ty,1}},N} where N}} where Ti&lt;:Real where Tw&lt;:Real where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.fit!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">fit!(estimator, num_iterations, X, y[, test...]; [verbosity = 1, is_row_major = false])
fit!(estimator, X, y[, test...]; [verbosity = 1, is_row_major = false])</code></pre><p>Fit the <code>estimator</code> with features data <code>X</code> and label <code>y</code> using the X-y pairs in <code>test</code> as validation sets.</p><p>Return a dictionary with an entry for each validation set. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value at each iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>num_iterations::Int</code>: OPTIONAL – defaults to estimator.num_iterations if not provided</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>test::Tuple{Matrix{TX},Vector{Ty}}...</code>: optionally contains one or more tuples of X-y pairs of   the same types as <code>X</code> and <code>y</code> that should be used as validation sets.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li><li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>   indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia&#39;s default).</li><li><code>weights::Vector{Tw&lt;:Real}</code>: the training weights.</li><li><code>init_score::Vector{Ti&lt;:Real}</code>: the init scores.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/fit.jl#LL1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.loadmodel-Tuple{LGBMEstimator,String}" href="#LightGBM.loadmodel-Tuple{LGBMEstimator,String}"><code>LightGBM.loadmodel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">loadmodel(estimator, filename)</code></pre><p>Load the fitted model <code>filename</code> into <code>estimator</code>. Note that this only loads the fitted model—not the parameters or data of the estimator whose model was saved as <code>filename</code>.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>filename::String</code>: the name of the file that contains the model.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/utils.jl#LL52-L61">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator,AbstractArray{TX,2}}} where TX&lt;:Real" href="#LightGBM.predict-Union{Tuple{TX}, Tuple{LGBMEstimator,AbstractArray{TX,2}}} where TX&lt;:Real"><code>LightGBM.predict</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">predict(estimator, X; [predict_type = 0, num_iterations = -1, verbosity = 1,
is_row_major = false])</code></pre><p>Return a <strong>MATRIX</strong> with the labels that the <code>estimator</code> predicts for features data <code>X</code>. Use <code>dropdims</code> if a vector is required.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>X::Matrix{T&lt;:Real}</code>: the features data.</li><li><code>predict_type::Integer</code>: keyword argument that controls the prediction type. <code>0</code> for normal   scores with transform (if needed), <code>1</code> for raw scores, <code>2</code> for leaf indices, <code>3</code> for SHAP contributions.</li><li><code>num_iterations::Integer</code>: keyword argument that sets the number of iterations of the model to   use in the prediction. <code>&lt; 0</code> for all iterations.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li><li><code>is_row_major::Bool</code>: keyword argument that indicates whether or not <code>X</code> is row-major. <code>true</code>   indicates that it is row-major, <code>false</code> indicates that it is column-major (Julia&#39;s default).</li></ul><p>One can obtain some form of feature importances by averaging SHAP contributions across predictions, i.e. <code>mean(LightGBM.predict(estimator, X; predict_type=3); dims=1)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/predict.jl#LL2-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.savemodel-Tuple{LGBMEstimator,String}" href="#LightGBM.savemodel-Tuple{LGBMEstimator,String}"><code>LightGBM.savemodel</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">savemodel(estimator, filename; [num_iteration = -1])</code></pre><p>Save the fitted model in <code>estimator</code> as <code>filename</code>.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to use in the prediction.</li><li><code>filename::String</code>: the name of the file to save the model in.</li><li><code>num_iteration::Integer</code>: keyword argument that sets the number of iterations of the model that   should be saved. <code>&lt; 0</code> for all iterations.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/utils.jl#LL35-L45">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any,Any}} where Ty&lt;:Real where TX&lt;:Real" href="#LightGBM.search_cv-Union{Tuple{Ty}, Tuple{TX}, Tuple{LGBMEstimator,Array{TX,2},Array{Ty,1},Any,Any}} where Ty&lt;:Real where TX&lt;:Real"><code>LightGBM.search_cv</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">search_cv(estimator, X, y, splits, params; [verbosity = 1])</code></pre><p>Exhaustive search over the specified sets of parameter values for the <code>estimator</code> with features data <code>X</code> and label <code>y</code>. The iterable <code>splits</code> provides vectors of indices for the training dataset. The remaining indices are used to create the validation dataset.</p><p>Return an array with a tuple for each set of parameters value, where the first entry is a set of parameter values and the second entry the cross-validation outcome of those values. This outcome is a dictionary with an entry for the validation dataset and, if the parameter <code>is_training_metric</code> is set in the <code>estimator</code>, an entry for the training dataset. Each entry of the dictionary is another dictionary with an entry for each validation metric in the <code>estimator</code>. Each of these entries is an array that holds the validation metric&#39;s value for each dataset, at the last valid iteration.</p><p><strong>Arguments</strong></p><ul><li><code>estimator::LGBMEstimator</code>: the estimator to be fit.</li><li><code>X::Matrix{TX&lt;:Real}</code>: the features data.</li><li><code>y::Vector{Ty&lt;:Real}</code>: the labels.</li><li><code>splits</code>: the iterable providing arrays of indices for the training dataset.</li><li><code>params</code>: the iterable providing dictionaries of pairs of parameters (Symbols) and values to   configure the <code>estimator</code> with.</li><li><code>verbosity::Integer</code>: keyword argument that controls LightGBM&#39;s verbosity. <code>&lt; 0</code> for fatal logs   only, <code>0</code> includes warning logs, <code>1</code> includes info logs, and <code>&gt; 1</code> includes debug logs.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/search_cv.jl#LL1-L25">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.gain_importance-Tuple{LGBMEstimator,Integer}" href="#LightGBM.gain_importance-Tuple{LGBMEstimator,Integer}"><code>LightGBM.gain_importance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">gain_importance(estimator, num_iteration)
gain_importance(estimator)

Returns the importance of a fitted booster in terms of information gain across
all boostings, or up to `num_iteration` boostings</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/utils.jl#LL113-L119">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="LightGBM.split_importance-Tuple{LGBMEstimator,Integer}" href="#LightGBM.split_importance-Tuple{LGBMEstimator,Integer}"><code>LightGBM.split_importance</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia">split_importance(estimator, num_iteration)
split_importance(estimator)

Returns the importance of a fitted booster in terms of number of times feature was
used in a split across all boostings, or up to `num_iteration` boostings</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/IQVIA-ML/LightGBM.jl/blob/03b925beeb3f9361476737ff998bfd88a2096ce7/src/utils.jl#LL124-L130">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Monday 26 October 2020 09:21">Monday 26 October 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
